{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, merge, Lambda\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.recurrent import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.activations import relu\n",
    "from functools import partial\n",
    "clipped_relu = partial(relu, max_value=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_filter(x):\n",
    "    # Max over the best filter score (like ICRA paper)\n",
    "    max_values = K.max(x, 2, keepdims=True)\n",
    "    max_flag = tf.greater_equal(x, max_values)\n",
    "    out = x * tf.cast(max_flag, tf.float32)\n",
    "    return out\n",
    "\n",
    "def channel_normalization(x):\n",
    "    # Normalize by the highest activation\n",
    "    max_values = K.max(K.abs(x), 2, keepdims=True)+1e-5\n",
    "    out = x / max_values\n",
    "    return out\n",
    "\n",
    "def WaveNet_activation(x):\n",
    "    tanh_out = Activation('tanh')(x)\n",
    "    sigm_out = Activation('sigmoid')(x)  \n",
    "    return Merge(mode='mul')([tanh_out, sigm_out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ED_TCN(n_nodes, conv_len, n_classes, n_feat, max_len, \n",
    "            loss='categorical_crossentropy', causal=False, \n",
    "            optimizer=\"rmsprop\", activation='norm_relu',\n",
    "            return_param_str=False):\n",
    "    n_layers = len(n_nodes)\n",
    "\n",
    "    inputs = Input(shape=(max_len,n_feat))\n",
    "    model = inputs\n",
    "\n",
    "    # ---- Encoder ----\n",
    "    for i in range(n_layers):\n",
    "        # Pad beginning of sequence to prevent usage of future data\n",
    "        if causal: model = ZeroPadding1D((conv_len//2,0))(model)\n",
    "        model = Convolution1D(n_nodes[i], conv_len, border_mode='same')(model)\n",
    "        if causal: model = Cropping1D((0,conv_len//2))(model)\n",
    "\n",
    "        model = SpatialDropout1D(0.3)(model)\n",
    "        \n",
    "        if activation=='norm_relu': \n",
    "            model = Activation('relu')(model)            \n",
    "            model = Lambda(channel_normalization, name=\"encoder_norm_{}\".format(i))(model)\n",
    "        elif activation=='wavenet': \n",
    "            model = WaveNet_activation(model) \n",
    "        else:\n",
    "            model = Activation(activation)(model)            \n",
    "        \n",
    "        model = MaxPooling1D(2)(model)\n",
    "\n",
    "    # ---- Decoder ----\n",
    "    for i in range(n_layers):\n",
    "        model = UpSampling1D(2)(model)\n",
    "        if causal: model = ZeroPadding1D((conv_len//2,0))(model)\n",
    "        model = Convolution1D(n_nodes[-i-1], conv_len, border_mode='same')(model)\n",
    "        if causal: model = Cropping1D((0,conv_len//2))(model)\n",
    "\n",
    "        model = SpatialDropout1D(0.3)(model)\n",
    "\n",
    "        if activation=='norm_relu': \n",
    "            model = Activation('relu')(model)\n",
    "            model = Lambda(channel_normalization, name=\"decoder_norm_{}\".format(i))(model)\n",
    "        elif activation=='wavenet': \n",
    "            model = WaveNet_activation(model) \n",
    "        else:\n",
    "            model = Activation(activation)(model)\n",
    "\n",
    "    # Output FC layer\n",
    "    model = TimeDistributed(Dense(n_classes, activation=\"softmax\" ))(model)\n",
    "    \n",
    "    model = Model(input=inputs, output=model)\n",
    "    model.compile(loss=loss, optimizer=optimizer, sample_weight_mode=\"temporal\", metrics=['accuracy'])\n",
    "\n",
    "    if return_param_str:\n",
    "        param_str = \"ED-TCN_C{}_L{}\".format(conv_len, n_layers)\n",
    "        if causal:\n",
    "            param_str += \"_causal\"\n",
    "    \n",
    "        return model, param_str\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9d05b54142fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtrain_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtest_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "save_predictions = [False, True][1]\n",
    "viz_predictions = [False, True][1]\n",
    "viz_weights = [False, True][0]\n",
    "\n",
    "# dataset = [\"50Salads\", \"JIGSAWS\", \"MERL\", \"GTEA\"][0]\n",
    "\n",
    "# How many latent states/nodes per layer of network\n",
    "# Only applicable to the TCNs. The ECCV and LSTM  model suses the first element from this list.\n",
    "n_nodes = [64, 96]\n",
    "nb_epoch = 200\n",
    "video_rate = 3\n",
    "# conv = {'50Salads':25, \"JIGSAWS\":20, \"MERL\":5, \"GTEA\":25}[dataset]\n",
    "\n",
    "\n",
    "n_classes = data.n_classes\n",
    "train_lengths = [x.shape[0] for x in X_train]\n",
    "test_lengths = [x.shape[0] for x in X_test]\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "\n",
    "n_feat = data.n_features\n",
    "print(\"# Feat:\", n_feat)\n",
    "\n",
    "model_type = \"ED-TCN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- CVPR model ----------\n",
    "if model_type in [\"tCNN\", \"ED-TCN\", \"DilatedTCN\", \"TDNN\", \"LSTM\"]:\n",
    "    # Go from y_t = {1...C} to one-hot vector (e.g. y_t = [0, 0, 1, 0])\n",
    "    Y_train = [np_utils.to_categorical(y, n_classes) for y in y_train]\n",
    "    Y_test = [np_utils.to_categorical(y, n_classes) for y in y_test]\n",
    "\n",
    "    # In order process batches simultaneously all data needs to be of the same length\n",
    "    # So make all same length and mask out the ends of each.\n",
    "    n_layers = len(n_nodes)\n",
    "    max_len = max(np.max(train_lengths), np.max(test_lengths))\n",
    "    max_len = int(np.ceil(max_len / (2**n_layers)))*2**n_layers\n",
    "    print(\"Max length:\", max_len)\n",
    "\n",
    "    X_train_m, Y_train_, M_train = utils.mask_data(X_train, Y_train, max_len, mask_value=-1)\n",
    "    X_test_m, Y_test_, M_test = utils.mask_data(X_test, Y_test, max_len, mask_value=-1)\n",
    "        \n",
    "    if model_type == \"ED-TCN\":\n",
    "        model, param_str = tf_models.ED_TCN(n_nodes, conv, n_classes, n_feat, max_len, causal=causal, \n",
    "                                        activation='norm_relu', return_param_str=True) \n",
    "    \n",
    "    AP_train = model.predict(X_train_m, verbose=0)\n",
    "    AP_test = model.predict(X_test_m, verbose=0)\n",
    "    AP_train = utils.unmask(AP_train, M_train)\n",
    "    AP_test = utils.unmask(AP_test, M_test)\n",
    "\n",
    "    P_train = [p.argmax(1) for p in AP_train]\n",
    "    P_test = [p.argmax(1) for p in AP_test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
